{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "TOPTREE:\n",
    "    Top level Script file that runs entire pipeline for the project. \n",
    "    It reads in each functional code to run final NNT with results. \n",
    "    begin with importing raw data and to final output of NNT model\n",
    "      Please see the directory: 1. Master NOMIS >   Create_Clean_NOMIS_Features.ipynb\n",
    "                                2. master CDRC  >   Create_Clean_CDRC_Features.ipynb\n",
    "      These scripts create the raw features list from the online scraping of \n",
    "      Office of National Statistics sites\n",
    "\n",
    "After final master data is created, feature engineering is performed to choose\n",
    "the best features. This is done in the direectory: \n",
    "                                Master Feature Options > master_Options.ipynb\n",
    "    \n",
    "INPUT:      --None--\n",
    "\n",
    "OUTPUT:     UnifiedView_Master.csv       - RAW Unified View data cleaned \n",
    "            UV_nomis_Master.csv          - UV data merged with NOMIS \n",
    "            UV_nomis_cdrc_Master.csv     - UV data merged with NOMIS and CDRC  \n",
    "            uv_COMPLETE_mas\n",
    "            \n",
    "            ter_FINAL.csv - FINAL output (if any derived data products are created)  \n",
    "            VARs                         - all as this is a script\n",
    "\n",
    "\n",
    "RUN: \n",
    "\n",
    "@author:NPS\n",
    "Created on Wed 2020/01/14\n",
    "modified: \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import std libraries\n",
    "import os\n",
    "import time\n",
    "import timeit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import FSA project-created libraries\n",
    "from lib_UVMasterClean import UnifiedView_cleaning\n",
    "from lib_mergeUV_NOMIS import uv_merge_nomis\n",
    "from lib_mergeUV_CDRC import uv_merge_cdrc\n",
    "import lib_UVDerive as uv_D\n",
    "from lib_Options import Master_options\n",
    "from lib_DeleteRubbish import delete_rubbish\n",
    "from lib_Dummies import Master_dummies\n",
    "from lib_NNT import NNTRegressor\n",
    "from lib_RIO import train_RIO_model\n",
    "from lib_RIO import RIO_predictor\n",
    "\n",
    "os.makedirs('./csv', exist_ok=True)\n",
    "os.makedirs('./temp', exist_ok=True)\n",
    "keylist = '1_1_1_1_1_1_1_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. clean the UV raw data [~20 min to run]\n",
    "\n",
    "# identfy the file location of the raw data from UV and postcode dictionary:\n",
    "\n",
    "# rawUVpath = 'Q:/Inform/Strategic Surveillance/Sprint AI/DATA/Unified_View/_business_data_fhrs-latest-inspection__view_detail.csv'\n",
    "# rawUVpath = 'C:/Users/Neel.Savani-Patel/NEEL_tech/LOCAL_DATA/_business_data_fhrs-latest-inspection__view_detail.csv'\n",
    "rawUVpath = 'C:/Users/Victor.SalasAranda/Desktop/FSA/csv/_business_data_fhrs-latest-inspection__view_detail.csv'\n",
    "\n",
    "# ukpostcode = 'Q:/Inform/Strategic Surveillance/Sprint AI/DATA/ukpostcodes.csv'\n",
    "# ukpostcode = 'C:/Users/Neel.Savani-Patel/NEEL_tech/LOCAL_DATA/ukpostcodes.csv'\n",
    "ukpostcode = 'C:/Users/Victor.SalasAranda/Desktop/FSA/csv/ukpostcodes.csv'\n",
    "\n",
    "\n",
    "# define file name of output .csv file\n",
    "uv_clean_filename = './csv/UnifiedView_Master.csv'\n",
    "\n",
    "pd_UV = UnifiedView_cleaning(rawUVpath, ukpostcode, uv_clean_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. merge with NOMIS    [~10 min to run - memory issue warning]\n",
    "\n",
    "# using pd created above if already exist .....\n",
    "# pd_UV_nomis = uv_nomis.uv_merge_nomis()\n",
    "\n",
    "# else using the output .csv file created in cell above\n",
    "UV_master_path = './csv/UnifiedView_Master.csv'\n",
    "\n",
    "# nomis_path = 'Q:/Inform/Strategic Surveillance/Sprint AI/DATA/NOMIS_features/NOMIS_Features.csv'\n",
    "# nomis_path = 'C:/Users/Neel.Savani-Patel/NEEL_tech/LOCAL_DATA/NOMIS_Features.csv'\n",
    "nomis_path = 'C:/Users/Victor.SalasAranda/Desktop/FSA/csv/NOMIS_Features.csv'\n",
    "\n",
    "# define file name of output .csv file\n",
    "uvnomis_filename = './csv/UV_nomis_Master.csv'\n",
    "\n",
    "pd_UV_nomis = uv_merge_nomis(UV_master_path, nomis_path, uvnomis_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. merge with CDRC (~10min to run)\n",
    "\n",
    "# using pd created above if already exist .....\n",
    "# pd_UV_nomis = uv_nomis.uv_merge_nomis()\n",
    "\n",
    "# else using the output .csv file created in cell above\n",
    "uvnomis_path = './csv/UV_nomis_Master.csv'\n",
    "\n",
    "# cdrc_path = 'C:/Users/Neel.Savani-Patel/NEEL_tech/LOCAL_DATA/CDRC_features.csv'\n",
    "# cdrc_path = 'Q:/Inform/Strategic Surveillance/Sprint AI/DATA/CDRC_features/CDRC_features.csv'\n",
    "cdrc_path = 'C:/Users/Victor.SalasAranda/Desktop/FSA/csv/CDRC_features.csv'\n",
    "\n",
    "# define file name of output .csv file\n",
    "uvcdrc_filename = './csv/UV_nomis_cdrc_Master.csv'\n",
    "\n",
    "pd_UV_nomis = uv_merge_cdrc(uvnomis_path, cdrc_path, uvcdrc_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. merge with derived data products (~4 min to run)\n",
    "\n",
    "#%%  4a  SEASONALITY of inspection\n",
    "uvcdrc_path = './csv/UV_nomis_cdrc_Master.csv'  # the output .csv file created in cell above\n",
    "uvder_name01 = './csv/UV_derive1.csv' # define file name of output .csv file\n",
    "pd_UV_der01 = uv_D.uv_seasonality(uvcdrc_path, uvder_name01)\n",
    "\n",
    "# %%  4b  CHAIN RESTURANT (~4 min to run)\n",
    "uv_path = './csv/UV_derive1.csv'\n",
    "uvder_name02 = './csv/UV_derive2.csv'\n",
    "pd_UV_der02 = uv_D.uv_chain(uv_path, uvder_name02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. DEFINE FULL AND TOTAL MASTERLIST OF EVERYTHING\n",
    "MASTER_FINAL = './csv/uv_COMPLETE_master_FINAL.csv'\n",
    "pd_UV_der02.to_csv(MASTER_FINAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_UV_der02.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cull / Clean / Prepare for Neural Net\n",
    "### perform in another TOPTREE script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Select the options files [~2-3 min to run]\n",
    "\n",
    "# Identfy the file location of the master dataset\n",
    "# I_data_path = 'Q:/Inform/Strategic Surveillance/Sprint AI/DATA/Unified_View/UnifiedView_NOMIS_CDRC_Seasonality_ChainOrNot.csv'\n",
    "I_data_path = './csv/uv_COMPLETE_master_FINAL.csv'\n",
    "\n",
    "# Select the keys\n",
    "# max. arguments = [3, 5, 6, 5, 4, 2, 4, 2]\n",
    "I_keyarray = [1, 1, 1, 1, 1, 1, 1, 1]\n",
    "\n",
    "# define file name of output .csv file\n",
    "I_out_filename = 'master'\n",
    "\n",
    "# function\n",
    "keylist, Data6 = Master_options(I_data_path, I_keyarray, I_out_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Delete all the features from one csv  [~2-3 min to run]\n",
    "# identfy the file location of the master dataset\n",
    "I_pd_Masterlist = './csv/master_'+ keylist+ '.csv' \n",
    "\n",
    "# csv with the features deletion\n",
    "I_csvfilename_of_features = './csv/Feature Deletion.csv'\n",
    "\n",
    "# define file name of output .csv file\n",
    "I_out_filename = 'clean_master_'+ keylist\n",
    "\n",
    "# To see the delete list: (Options: 'Yes', 'No')\n",
    "Bool = 'No' \n",
    "\n",
    "# function\n",
    "Data7 = delete_rubbish(I_pd_Masterlist, I_csvfilename_of_features, I_out_filename, Bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Create and add dummies features to the master csv (and delete categorical ones)  [~1-2 min to run]\n",
    "# identfy the file location of the master dataset\n",
    "I_data_path = './csv/clean_master_'+ keylist+ '.csv' \n",
    "\n",
    "# define file name of output .csv file\n",
    "I_out_filename = 'master_dummies_'+ keylist\n",
    "\n",
    "# Max number of dummies for each feature allowed (if ones have less that Max, those features will be removed)\n",
    "Max = 50\n",
    "\n",
    "# function\n",
    "Data8 = Master_dummies(I_data_path, I_out_filename, Max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 9. Create and train a NNT  [60~ min to run: it depends on how many models]\n",
    "lastime=time.time()\n",
    "# identfy the file location of the master dataset\n",
    "I_data_path = './csv/master_dummies_'+ keylist+ '.csv' \n",
    "\n",
    "# Parameters\n",
    "k = 4\n",
    "num_epochs = 100\n",
    "batch_Size = 128\n",
    "\n",
    "# types of Models (Possibilities: 1 to 6, you can choose how many you want e.g: [2,3,1,6])\n",
    "NNTList =[6]  \n",
    "\n",
    "# Function\n",
    "train_data, train_targets, test_data, test_targets = NNTRegressor(I_data_path, k, num_epochs, batch_Size, NNTList, keylist)\n",
    "print((time.time()-lastime)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
